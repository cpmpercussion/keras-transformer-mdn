{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDN-transformer with examples\n",
    "\n",
    "- What kind of data can be predicted by a mixture density network Transformer?\n",
    "    - Continuous sequential data\n",
    "- Drawing data and RoboJam Touch Screem would be good examples for this, continuous values yield high resolution in 2d space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kanji Generation\n",
    "\n",
    "- Firstly, let's try modelling some drawing data for Kanji writing using an MDN-Transformer.\n",
    "\n",
    "- This work is inspired by previous work \"MDN-RNN for Kanji Generation\", hardmaru's Kanji tutorial and the original Sketch-RNN repository:\n",
    "\n",
    "    - http://blog.otoro.net/2015/12/28/recurrent-net-dreams-up-fake-chinese-characters-in-vector-format-with-tensorflow/\n",
    "    - https://github.com/hardmaru/sketch-rnn\n",
    "\n",
    "    - The idea is to learn how to draw kanji characters from a dataset of vector representations. \n",
    "    - This means learning how to move a pen in 2D space.\n",
    "    - The data consists of a sequence of pen movements (loations in 2D) and whether the pen is up or down.\n",
    "    - In this example, we will use one 3D MDN to model everything!\n",
    "\n",
    "We will end up with a system that will continue writing Kanji given a short sequence, like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and modules\n",
    "import sys\n",
    "!{sys.executable} -m pip install keras-mdn-layer \n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install tensorflow-probability\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install svgwrite\n",
    "\n",
    "import mdn\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "%matplotlib notebook\n",
    "\n",
    "# Only for GPU use:\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and process the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train from David Ha's Kanji dataset from Sketch-RNN: https://github.com/hardmaru/sketch-rnn-datasets\n",
    "# Other datasets in \"Sketch 3\" format should also work.\n",
    "import urllib.request\n",
    "# url = 'https://github.com/hardmaru/sketch-rnn-datasets/raw/master/kanji/kanji.rdp25.npz'  \n",
    "# urllib.request.urlretrieve(url, './kanji.rdp25.npz')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Includes about 11000 handwritten kanji characters divied into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('./kanji.rdp25.npz', allow_pickle=True) as data:\n",
    "    train_set = data['train']\n",
    "    valid_set = data['valid']\n",
    "    test_set = data['test']\n",
    "    \n",
    "print(\"Training kanji:\", len(train_set))\n",
    "print(\"Validation kanji:\", len(valid_set))\n",
    "print(\"Testing kanji:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for slicing up data\n",
    "def slice_sequence_examples(sequence, num_steps):\n",
    "    xs = []\n",
    "    for i in range(len(sequence) - num_steps - 1):\n",
    "        example = sequence[i: i + num_steps]\n",
    "        xs.append(example)\n",
    "    return xs\n",
    "\n",
    "def seq_to_singleton_format(examples):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ex in examples:\n",
    "        xs.append(ex[:SEQ_LEN])\n",
    "        ys.append(ex)\n",
    "    return xs, ys\n",
    "\n",
    "# Functions for making the data set\n",
    "def format_dataset(x, y):\n",
    "    return ({\n",
    "        \"input\": x,\n",
    "        \"target\": y[:, :-1, :],\n",
    "    }, y[:, 1:, :])\n",
    "\n",
    "def make_dataset(X, y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shapes\n",
    "NUM_FEATS = 3\n",
    "SEQ_LEN = 20\n",
    "gap_len = 1\n",
    "batch_size = 128\n",
    "\n",
    "# Prepare training data as X and Y.\n",
    "slices = []\n",
    "for seq in train_set:\n",
    "    slices += slice_sequence_examples(seq, SEQ_LEN+gap_len)\n",
    "X, y = seq_to_singleton_format(slices)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "train_ds = make_dataset(X, y)\n",
    "print(\"Number of training examples:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the MDN Transformer\n",
    "\n",
    "Our MDN Transformer has the following settings:\n",
    "- an embedding layer with positional embedding\n",
    "- a transformer encoder\n",
    "- a transformer decoder\n",
    "- a three-dimensional mixture layer with 10 mixtures\n",
    "- train for sequence length ___\n",
    "- training for ___ epochs with a batch size of ___\n",
    "\n",
    "Here's a diagram:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Dense(output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "    def call(self, inputs, padding_mask=None):\n",
    "        length = inputs.shape[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    \n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "    def call(self, inputs, mask=None):\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "    def call(self, inputs, encoder_outputs, padding_mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        if padding_mask==None:\n",
    "            attention_output_2 = self.attention_2(\n",
    "                query=attention_output_1,\n",
    "                value=encoder_outputs,\n",
    "                key=encoder_outputs)\n",
    "        else:\n",
    "            attention_output_2 = self.attention_2(\n",
    "                query=attention_output_1,\n",
    "                value=encoder_outputs,\n",
    "                key=encoder_outputs,\n",
    "                attention_mask=padding_mask)\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters:\n",
    "input_dim = 3\n",
    "sequence_length = 20\n",
    "target_length = 20\n",
    "embed_dim = 256\n",
    "dense_dim = 128\n",
    "num_heads = 2\n",
    "output_dim = 3\n",
    "number_mixtures = 10\n",
    "\n",
    "EPOCHS = 20\n",
    "SEED = 2345  # set random seed for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(sequence_length, input_dim), dtype=\"float64\", name=\"input\")\n",
    "x = PositionalEmbedding(sequence_length, input_dim, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "print(encoder_outputs.shape)\n",
    "# encoder_outputs2 = TransformerEncoder(embed_dim, dense_dim, num_heads)(encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(target_length, input_dim), dtype=\"float64\", name=\"target\")\n",
    "x = PositionalEmbedding(target_length, input_dim, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "# x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs2)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "decoder_outputs = layers.Dense(input_dim, activation=\"softmax\")(x)\n",
    "outputs = mdn.MDN(output_dim, number_mixtures) (decoder_outputs)\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], outputs)\n",
    "model.compile(loss=mdn.get_mixture_loss_func(output_dim,number_mixtures), \n",
    "              optimizer=keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"full_transformer.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "history=model.fit(train_ds, batch_size=batch_size, epochs=EPOCHS, callbacks=callbacks)\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model.save('my_model_100_128_256_128_2_02')\n",
    "\n",
    "# print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls saved_model/my_model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_model/my_model6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating drawings\n",
    "\n",
    "First need some helper functions to view the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_start_position():\n",
    "    \"\"\"A zeroed out start position with pen down\"\"\"\n",
    "    out = np.zeros((1, 1, 3), dtype=np.float32)\n",
    "    out[0, 0, 2] = 1 # set pen down.\n",
    "    return out\n",
    "\n",
    "def generate_sketch(model, start_pos, num_points=100):\n",
    "     return None\n",
    "\n",
    "def cutoff_stroke(x):\n",
    "    return np.greater(x,0.5) * 1.0\n",
    "\n",
    "def plot_sketch(sketch_array):\n",
    "    \"\"\"Plot a sketch quickly to see what it looks like.\"\"\"\n",
    "    sketch_df = pd.DataFrame({'x':sketch_array.T[0],'y':sketch_array.T[1],'z':sketch_array.T[2]})\n",
    "    sketch_df.x = sketch_df.x.cumsum()\n",
    "    sketch_df.y = -1 * sketch_df.y.cumsum()\n",
    "    # Do the plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    #ax1.scatter(sketch_df.x,sketch_df.y,marker='o', c='r', alpha=1.0)\n",
    "    # Need to do something with sketch_df.z\n",
    "    ax1.plot(sketch_df.x,sketch_df.y,'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVG Drawing Function\n",
    "\n",
    "Here's Hardmaru's Drawing Functions from _write-rnn-tensorflow_. Big hat tip to Hardmaru for this!\n",
    "\n",
    "Here's the source: https://github.com/hardmaru/write-rnn-tensorflow/blob/master/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "def get_bounds(data, factor):\n",
    "    min_x = 0\n",
    "    max_x = 0\n",
    "    min_y = 0\n",
    "    max_y = 0\n",
    "\n",
    "    abs_x = 0\n",
    "    abs_y = 0\n",
    "    for i in range(len(data)):\n",
    "        x = float(data[i, 0]) / factor\n",
    "        y = float(data[i, 1]) / factor\n",
    "        abs_x += x\n",
    "        abs_y += y\n",
    "        min_x = min(min_x, abs_x)\n",
    "        min_y = min(min_y, abs_y)\n",
    "        max_x = max(max_x, abs_x)\n",
    "        max_y = max(max_y, abs_y)\n",
    "\n",
    "    return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "def draw_strokes(data, factor=1, svg_filename='sample.svg'):\n",
    "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "\n",
    "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=dims, fill='white'))\n",
    "\n",
    "    lift_pen = 1\n",
    "\n",
    "    abs_x = 25 - min_x\n",
    "    abs_y = 25 - min_y\n",
    "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "\n",
    "    command = \"m\"\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i, 0]) / factor\n",
    "        y = float(data[i, 1]) / factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command + str(x) + \",\" + str(y) + \" \"\n",
    "\n",
    "    the_color = \"black\"\n",
    "    stroke_width = 1\n",
    "\n",
    "    dwg.add(dwg.path(p).stroke(the_color, stroke_width).fill(\"none\"))\n",
    "\n",
    "    dwg.save()\n",
    "    display(SVG(dwg.tostring()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = valid_set[0]\n",
    "x0 = np.array([valid_set[0][:SEQ_LEN]])\n",
    "y0 = x0\n",
    "# y0 = np.array([valid_set[0][:(SEQ_LEN+9)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a character and plot the result.\n",
    "pi_temperature = 3 # seems to work well with rather high temperature (2.5)\n",
    "sigma_temp = 0.1 # seems to work well with low temp\n",
    "\n",
    "### Generation using one example from validation set as \n",
    "p = x0\n",
    "sketch = p\n",
    "\n",
    "for i in range(100):\n",
    "    params = model.predict([p, p])\n",
    "    out = mdn.sample_from_output(params[0][49], output_dim, number_mixtures, temp=pi_temperature, sigma_temp=sigma_temp)\n",
    "    p = np.concatenate((p[:,1:],np.array([out])), axis=1)\n",
    "    sketch = np.concatenate((sketch, np.array([out])), axis=1)\n",
    "\n",
    "sketch.T[2] = cutoff_stroke(sketch.T[2])\n",
    "draw_strokes(sketch[0], factor=0.5)\n",
    "draw_strokes(x0[0], factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
